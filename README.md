# Real-Time-Emotion-Based-Frequency-Recommendation-System
A project that detects emotion using a webcam and recommends a frequency based on the emotion
This project is a real-time system that detects emotions from facial expressions using a live camera feed and predicts a personalized frequency recommendation based on various factors, including the detected emotion, gender, time, location, weather, activity, feedback, age, mood intensity, and sleep quality. The recommended frequency is then played on an online tone generator for practical use.

#Overview
This project combines two machine learning models:

Emotion Recognition Model: Detects emotions in real-time using the camera feed.
Frequency Recommendation Model: Recommends a frequency based on detected emotion and additional user inputs.
The integration of these models is implemented in the emotion_frequency.py script, which allows users to input details, capture real-time emotion, and receive a frequency recommendation played on the Online Tone Generator.

#Datasets
